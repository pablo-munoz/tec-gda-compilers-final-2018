#+TITLE: Natural language text to python code transpiler
#+LATEX_HEADER: \usepackage[margin=0.5in]{geometry}


* Requirements
1. Every paragraph will be a new class. And if in the source file
   contains the same paragraph there would be two identical classes,
   this would ont be an error.
2. 
3. Class properties must be declared together in a sentence after the
   class declaration sentence, separated by commas

* Code
** The =main= program
Our main program will consist of a command line interface that takes
as input the path to a text file containing natural language and
outputs the program constructed from it to stdout.

#+BEGIN_SRC python :tangle src/main.py
import sys
import argparse
import logging
import os

logging_level = logging.CRITICAL

if os.environ.get('DEBUG'):
    logging_level = logging.DEBUG

logging.basicConfig(level=logging_level)
logger = logging.getLogger(__file__)

from transpiler import Transpiler

if __name__ == '__main__':
    argument_parser = argparse.ArgumentParser()

    argument_parser.add_argument(
        '-i', '--input', type=str,
        help='Path to text file with program description in natural language')

    args = argument_parser.parse_args(sys.argv[1:])

    input_ = args.input
    logger.debug('input: {}'.format(input_))

    with open(input_, 'r') as fhandle:
        text = fhandle.read()

    transpiler = Transpiler()
    transpiler.transpile(text)
#+END_SRC

** =class Transpiler=
Although not perfectly accurate for our task, we take the liberty of
calling the process of taking a text in natural language and
converting it into code *transpilation*.

#+BEGIN_SRC python :tangle src/transpiler.py :noweb yes :exports none
import re
import logging
import nltk

logger = logging.getLogger(__file__)

# Regular expression to separate the paragraphs of the input
# text into separate strings.
paragraph_regex = re.compile('\n\n+', re.UNICODE)

class Transpiler:

    def transpile(self, text):
        paragraphs = self.tokenize_paragraphs(text)
        logger.debug('paragraphs: {}'.format(paragraphs))

        self.produce_class_code({
            'name': 'Dog',
            'attributes': {
                'mood': 'HAPPY',
                'energy': 100,
                'coordinatePosition': (0, 0)
            }
        })

    <<split_paragraphs>>
    <<parse_class_paragraph>>
    <<produce_class_code>>
    <<tokenize_words>>
    <<part_of_speech_tag>>
#+END_SRC

*** =split_paragraphs(self, text)=
One of the constraints of our system is that each class must be
defined in a paragraph of natural language text. We can use this to
our advantage by splitting the paragraphs into separate strings, this
way we can focus on one at a time in other methods.

#+NAME: split_paragraphs
#+BEGIN_SRC python :noweb yes
def split_paragraphs(self, text):
    '''
    Returns a list of strings. Each strings is a paragraph in the
    given text.

    Arguments:
    text -- string assumed to contain one or more paragraphs, where a
      paragraph is defined as consecutive lines, i.e. two consecutive
      line breaks demarcate a paragraph.
    
    Usage:
    >>> two_paragraphs_together = """this is the
    ... first paragraph
    ...
    ... and this is the
    ... second
    ... """
    >>> transpiler = Transpiler()
    >>> separated_paragraphs = transpiler.split_paragraphs(two_paragraphs_together)
    >>> print(separated_paragraphs[0])
    this is the
    first paragraph
    >>> print(separated_paragraphs[1])
    and this is the
    second
    '''
    return list(map(lambda s: s.strip('\n'), paragraph_regex.split(text)))

#+END_SRC

*** =parse_class_paragraph(self, paragraph)=
This method takes a paragraph of the natural language program as a
string and parses it. By parsing we mean it is transformed into
an internal representation (a dictionary in this case), that other
methods can use to produce a code representation. For the purposes
of this system, the =paragraph= will always be a string that has
been generated by the =split_paragraphs= method.

The process of how we parse a paragraph string into its internal
dictionary representation can be split into TODO steps:

1. Lowercase paragraph
1. Tokenizing words
2. POS-tagging (part-of-speech tagging)
3. Parsing class name
4. Parsing attributes
5. Parsing methods
   
#+NAME: parse_class_paragraph
#+BEGIN_SRC python :noweb yes
def parse_class_paragraph(self, paragraph):
    '''Returns a dictionary that contains an internal representation of
    a python class given as a natural language string *paragraph*.
    
    Arguments:
    paragraph -- str, Natural language string describing a python class.
    
    Usage:
    >>> paragraph = """
    ... A dog is a Class. He has mood = “HAPPY”, energy = 100,
    ... coordenatePosition = (0,0). He can Bark, Run, MoveLeft, MoveRight,
    ... MoveForward, Lay and Check. To Run he used MoveForward(2), his energy
    ... decreases in 1, his mood is “PLAY” and return 0. To MoveForward he
    ... needs numbersSteps, his coordinatePosition[0] increases in
    ... numbersSteps, his mood is “MOVING”, decreases energy by 1. To MoveLeft
    ... he needs numbersSteps, his coordinatePosition[1] decreases in
    ... numbersSteps, his mood is “MOVING”, decreases energy by 1. To
    ... MoveRight he needs numbersSteps, his coordinatePosition[1] increases
    ... in numbersSteps, his mood is “MOVING”, decreases energy by 1. To Bark
    ... he print “barf, barf”, his energy decreases in 1, his mood is
    ... “BARKING”. To Lay he used print “relax”, he used print “move the
    ... Booty”, his energy increases in 3. To Check he print “mood: ” +
    ... self.mood, he print “energy: “ + str(self.energy), print “Position” +
    ... str(self.coordinatePosition)
    ... """
    >>> transpiler = Transpiler()
    >>> class_metadata = transpiler.parse_class_paragraph(paragraph)
    >>> class_metadata['class_name']
    'dog'
    >>> class_metadata['property_names_and_defaults']
    [('mood', '“happy”'), ('energy', '100'), ('coordenateposition', '(0,0)')]
    '''
    # 1. Lowercase paragraph
    lowercase_paragraph = paragraph.lower()
    # 2. Tokenize words
    word_tokens = self.tokenize_words(lowercase_paragraph)
    # 3. POS-tagging
    tagged_word_tokens = self.part_of_speech_tag(word_tokens)

    class_name = None
    <<parse_class_name>>

    property_names_and_defaults = []
    <<parse_property_names_and_defaults>>

    # TODO parse methods

    return dict(
        class_name=class_name,
        property_names_and_defaults=property_names_and_defaults
    )

#+END_SRC

To parse the classname we exploit the following restriction of the
system: /A class is declared as a sentence whose last two elements
are the word 'class' and a period. The class declaring sentence
must be the first sentence in a class paragraph/

The strategy we will employ is to find the first period within
the paragraph =tagged_word_tokens=, then look back for the first
noun (tag 'NN') we encounter, that will be the name of the class.

#+NAME: parse_class_name
#+BEGIN_SRC python :noweb yes
class_keyword_index = word_tokens.index('class')
first_noun_before_class_keyword = next(filter(
    lambda pair: pair[1] == 'NN',
    tagged_word_tokens[class_keyword_index-1:0:-1]))[0]
class_name = first_noun_before_class_keyword

#+END_SRC

In order to parse the property names and default values of a class we
make use of another constraint of the system and parse the second
sentence of the paragraph since: /Class properties must be declared
together in a sentence after the class declaration sentence, the
declarations must be of the form <property name> = <default value>,
where the default values can be any valid python expression. The
properties declarations must be separated by commas/.

#+NAME: parse_property_names_and_defaults
#+BEGIN_SRC python :noweb yes
index_of_first_word_second_sentence = (
    class_keyword_index +
    1 + # Because of the dot that finalizes the class declaration
    1 # the word after the dot
)

i = 0
j = index_of_first_word_second_sentence
while True:
    next_word = word_tokens[j + i]
    if next_word == '.':
        break

    if next_word == '=':
        # The property name is the word before the = symbol
        property_name = word_tokens[j + i - 1]

        # The property default value is the concatenations of all
        # the words/tokens after the = symbol and before the next
        # immediate comma or period.
        property_default_value = ''

        i += 1
        next_word = word_tokens[j + i]

        while next_word not in ('.', ','):
            property_default_value += next_word
            i += 1
            next_word = word_tokens[j + i]

        property_names_and_defaults.append((property_name, property_default_value))

        i -= 1

    else:
        i += 1
#+END_SRC


*** =tokenize_words(self, string)=
Wrapper around =nltk='s =word_tokenize=.

#+NAME: tokenize_words
#+BEGIN_SRC python
def tokenize_words(self, string):
    '''Returns a list of the words contained in string which is assumed
    to be a sentence.

    Arguments:
    string -- string represeting a sentence
    
    Usage:
    >>> transpiler = Transpiler()
    >>> transpiler.tokenize_words('a dog is a class.')
    ['a', 'dog', 'is', 'a', 'class', '.']
    '''
    return nltk.word_tokenize(string)

#+END_SRC

*** =part_of_speech_tag(self, tokens)=
#+NAME: part_of_speech_tag
#+BEGIN_SRC python :noweb yes
def part_of_speech_tag(self, tokens):
    '''Returns a list of (word, tag) tuples for each word in tokens.

    Tags are strings that represent the role that a word takes in a text.
    For example a tag of 'NN' means the word is a noun, a tag of 'VBZ'
    means a verb, present tense, 3rd person singular. To know what a
    particular tag means you can run the following code:

    nltk.help.upenn_tagset('<TAG>')

    Arguments:
    tokens -- list of words (str)
    
    Usage:
    >>> transpiler = Transpiler()
    >>> tokens = transpiler.tokenize_words('a dog is a class')
    >>> transpiler.part_of_speech_tag(tokens)
    [('a', 'DT'), ('dog', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('class', 'NN')]
    '''
    return nltk.pos_tag(tokens)
#+END_SRC

*** =produce_class_code(self, class_metadata)=
This method produces the code for a class represented by a dictionary
of class attributes and methods given as the =class_metadata=
parameter.

#+NAME: produce_class_code
#+BEGIN_SRC python :noweb yes
def produce_class_code(self, class_metadata):
    '''
    '''
    print('class {name}:'.format(**class_metadata))
    for name, value in class_metadata['attributes'].items():
        print_value=value
        if isinstance(value, str):
            print_value = '"{value}"'.format(value=value)
        print('    {name} = {value}'.format(name=name, value=print_value))

#+END_SRC
